workdir:
  Linux: /data/kyy/workspace/ctr/hdfs_ctr/
  Windows: E:/Work/jobs/data/DSP/CTR预估/samples/
defaultID:
  '99999999'
window: 7
fields_use_strategy:
  history: true
  realtime: true
  personas: true
  context: true
  creativeTime: true
xgboost:
  booster: 'gbtree'
  objective: 'binary:logistic'  # 多分类的问题
  # 'num_class': 10,  # 类别数，与 multisoftmax 并用
  gamma: 0.1  # 用于控制是否后剪枝的参数,越大越保守，一般0.1、0.2这样子。
  max_depth: 4  # 构建树的深度，越大越容易过拟合
  lambda: 2 # 控制模型复杂度的权重值的L2正则化项参数，参数越大，模型越不容易过拟合。
  subsample: 0.7  # 随机采样训练样本
  colsample_bytree: 0.7  # 生成树时进行的列采样
  min_child_weight: 3
  silent: 0  # 设置成1则没有运行信息输出，最好是设置为0.
  eta: 0.05  # 如同学习率
  seed: 1000
  nthread: 4  # cpu 线程数
  n_estimators: 50
gbdt:
  loss: 'deviance'
  learning_rate: 0.1
  n_estimators: 100
xgboost_plus_lr:
  loss: 'deviance'
  learning_rate: 0.1
  n_estimators: 100
xgboost_plus_ffm:
  phase: train
  xgboost:
    loss: 'deviance'
    learning_rate: 0.1
    n_estimators: 30
    max_depth: 3
  ffm:
    task: binary
    lr: 0.2
    lambda: 0.002
    epoch: 20
    metric: auc
    k : 4
lightgbm_plus_ffm:
  phase: train
  lightgbm:
    metric: 'binary_logloss'
    objective: binary
    learning_rate: 0.05
    n_estimators: 20
    num_leaves: 31
    scale_pos_weight: 2
  ffm:
    task: binary
    lr: 0.05
    lambda: 0.002
    epoch: 20
    metric: auc
    k : 4
    opt: adagrad
ffm:
    phase: train
    task: binary
    lr: 0.2
    lambda: 0.002
    epoch: 20
    metric: auc
    k : 4

